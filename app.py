from collections import deque
from datetime import datetime
from random import randint
from PIL import ImageFile

import streamlit as st
import pandas as pd
import cv2 as cv

import shutil
import os

from src.img_capture import open_capture, close_capture, capture_frame
from src.inference import infer_image
from src.analysis import analyse_daily_activity, analyse_total_activity
from src.utils import get_dataframe_row, image_to_base64
from src.gif import make_gif

ImageFile.LOAD_TRUNCATED_IMAGES = True

LOG_DIR = 'logs'
FRAME_DIR = 'frames'
CAPTURE_DIR = 'captures'
BBOX_DIR = 'bbox'

PLACEHOLDER = 'resources/placeholder.png'
CAM_BLIND = 'resources/cam_blind.png'
SOURCE_VIDEO = 'resources/demo.mp4'

BEEPS = {
    'ì•Œë¦¼ìŒ ë„ê¸°': '',
    'ê¸°ë³¸ ì•Œë¦¼ìŒ': 'https://www.soundjay.com/buttons/sounds/beep-07a.mp3',
    'ë©ë©': 'https://t1.daumcdn.net/cfile/tistory/99CC98395CE6F54B0A'
}
BEHAVIORS = ['FEETUP', 'SIT', 'WALK', 'LYING', 'BODYSHAKE']
NODOG = 'ê°•ì•„ì§€ ì—†ìŒ'


os.makedirs(BBOX_DIR, exist_ok=True)
os.makedirs(FRAME_DIR, exist_ok=True)
os.makedirs(CAPTURE_DIR, exist_ok=True)


def load_logs(log_dir='logs/'):
    logs = []
    for i, file_name in enumerate(os.listdir(log_dir)):
        df = pd.read_csv(os.path.join(log_dir, file_name))
        logs.append(df)
    if not logs:
        logs.append(pd.DataFrame(columns=['ë‚ ì§œ', 'ì‹œê°„', 'í–‰ë™']))
    log = logs.pop()
    logs.reverse()
    return log, logs


"""
ìƒíƒœ ìƒì„±
"""

if 'placeholder' not in st.session_state:
    st.session_state.placeholder = 0 
if 'log' not in st.session_state:
    st.session_state.log, st.session_state.logs = load_logs()
if 'behavior' not in st.session_state:
    st.session_state.behavior = NODOG
if 'beep' not in st.session_state:
    st.session_state.beep = list(BEEPS.keys())[1]
if 'noti_filter' not in st.session_state:
    st.session_state.noti_filter = []
if 'log_filter' not in st.session_state:
    st.session_state.log_filter = []
if 'log_expanded' not in st.session_state:
    st.session_state.log_expanded = {}
if 'is_mic_on' not in st.session_state:
    st.session_state.is_mic_on = False
if 'is_cam_on' not in st.session_state:
    st.session_state.is_cam_on = True
    
if 'demo_cap' not in st.session_state:
    st.session_state.demo_cap = open_capture(SOURCE_VIDEO)
if 'live_cap' not in st.session_state:
    # st.session_state.live_cap = open_capture(0)
    st.session_state.live_cap = st.session_state.demo_cap

if 'frames' not in st.session_state:
    frames = os.listdir(FRAME_DIR)
    for i in range(len(frames)):
        frame = frames[i]
        timestamp = datetime.strptime(frame[:-4], r'%Y-%m-%d %H_%M_%S_%f')
        frames[i] = (os.path.join(FRAME_DIR, frame), timestamp)
    frames = deque(frames)
    st.session_state.frames = frames
if 'bbox_frames' not in st.session_state:
    bbox_frames = os.listdir(BBOX_DIR)
    for i in range(len(bbox_frames)):
        file_path = bbox_frames[i]
        file_name = os.path.basename(file_path)
        if len(file_name[:-4].split(maxsplit=3)) != 4:
            continue
        d, t, has_dog, behavior = file_name[:-4].split(maxsplit=3)
        timestamp = datetime.strptime(f'{d} {t}', r'%Y-%m-%d %H_%M_%S_%f')
        bbox_frames[i] = (file_path, timestamp, has_dog, behavior)
    bbox_frames = deque(bbox_frames)
    st.session_state.bbox_frames = bbox_frames
if 'is_demo' not in st.session_state:
    st.session_state.is_demo = True
if 'gif_queue' not in st.session_state:
    st.session_state.gif_queue = deque()


def add_log(tiemstamp, behavior, image_path, notify=True):
    row = get_dataframe_row(tiemstamp.date(), tiemstamp.time(), behavior, image_path)
    if st.session_state.log.empty or st.session_state.log.iloc[0]['ë‚ ì§œ'] == row.iloc[0]['ë‚ ì§œ']:
        st.session_state.log = pd.concat([row, st.session_state.log], ignore_index=True)
    else:
        st.session_state.logs.insert(0, st.session_state.log)
        st.session_state.log = row
    if not st.session_state.log.empty:
        st.session_state.log.to_csv(os.path.join(LOG_DIR, st.session_state.log.iloc[0]['ë‚ ì§œ'] + '.csv'), index=False)
    if notify and behavior in st.session_state.noti_filter:
        st.html(
            f'<audio autoplay><source src="{BEEPS[st.session_state.beep]}" type="audio/mpeg"></audio>'
        )
        st.toast(f'í–‰ë™ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤: {behavior}', icon='ğŸ¶')
    st.session_state.behavior = behavior


"""
í”„ë˜ê·¸ë¨¼íŠ¸ ìƒì„±
"""


@st.fragment(run_every='100ms')
def realtime_image():
    if st.session_state.is_cam_on:
        image = ''
        if frames := os.listdir(FRAME_DIR):
            image = os.path.join(FRAME_DIR, frames[-1])
        if not os.path.exists(image):
            image = PLACEHOLDER
    else:
        image = CAM_BLIND
    st.image(image, use_container_width=True)


@st.fragment(run_every='100ms')
def dataframe_brief():
    st.dataframe(
        st.session_state.log.head(10), 
        use_container_width=True, hide_index=True,
        column_config={
            'íŒŒì¼': st.column_config.LinkColumn(display_text="íƒìƒ‰ê¸°ì—ì„œ ì—´ê¸°")
        }
    )


@st.fragment(run_every='100ms')
def entire_dataframes():
    has_no_data = True
    is_first = True
    logs = [st.session_state.log] + st.session_state.logs
    with st.container():
        for df in logs:
            if st.session_state.log_filter:
                df = df[df['í–‰ë™'].isin(st.session_state.log_filter)]
            if df.empty:
                continue
            has_no_data = False
            
            date = df.iloc[0]['ë‚ ì§œ']
            if date not in st.session_state.log_expanded:
                st.session_state.log_expanded[date] = is_first
            is_first = False
            
            with st.expander(date, expanded=st.session_state.log_expanded[date]):
                st.dataframe(
                    df, 
                    use_container_width=True, hide_index=True, key=date,
                    column_config={
                        'íŒŒì¼': st.column_config.LinkColumn(display_text="íƒìƒ‰ê¸°ì—ì„œ ì—´ê¸°")
                    }
                )
        if has_no_data:
            st.caption('í–‰ë™ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.')


@st.fragment()
def toolbar():
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.session_state.is_mic_on = st.toggle(
            'ğŸ™ï¸ ë§ˆì´í¬', 
            value=False, 
            help='ì‹¤ì‹œê°„ìœ¼ë¡œ ì „ë‹¬ëœ ìŒì„±ì´ í™ˆìº ì˜ ìŠ¤í”¼ì»¤ì—ì„œ ì¬ìƒë©ë‹ˆë‹¤.'
        )
    with col2:
        st.session_state.is_cam_on = st.toggle(
            'ğŸ“¹ ì¹´ë©”ë¼', 
            value=True, 
            help='í™”ë©´ì—ì„œ ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í™”ë©´ì´ ê°€ë ¤ì§€ì§€ë§Œ, ë…¹í™”ì™€ ë¶„ì„ì€ ê³„ì† ì§„í–‰ë©ë‹ˆë‹¤.'
        )
    with col3:
        if st.button('ìº¡ì³í•˜ê¸°', icon='ğŸ“¸', use_container_width=True) and frames:
            image, timestamp = frames[-1]
            shutil.copy(image, CAPTURE_DIR)
            add_log(timestamp, st.session_state.behavior, os.path.join(CAPTURE_DIR, os.path.basename(image)), notify=False)
            st.toast('ìº¡ì³ëœ ì´ë¯¸ì§€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.', icon='ğŸ“¸')
    with col4:
        st.button('ì €ì¥ì†Œ ì—´ê¸°', icon='ğŸ“‚', use_container_width=True)


@st.fragment(run_every='100ms')
def mic_info():
    if st.session_state.is_mic_on:
        st.info('ë§ˆì´í¬ê°€ ì¼œì ¸ìˆìŠµë‹ˆë‹¤!', icon='ğŸ™ï¸')
    else:
        st.empty()


@st.fragment(run_every='5s')
def analysis():
    df = analyse_total_activity([st.session_state.log] + st.session_state.logs)
    cur = df.iloc[len(df) - 1]
    
    if -5.0 <= cur['í™œë™ëŸ‰ ë³€í™”'] <= 5.0:
        delta_str = 'ì „ë‚ ê³¼ ë¹„êµí–ˆì„ ë•Œ í™œë™ëŸ‰ì— í° ë³€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.'
    elif cur['í™œë™ëŸ‰ ë³€í™”'] > 5.0:
        delta_str = 'ì „ë‚ ì— ë¹„í•´ í™œë™ëŸ‰ì´ ì¦ê°€í–ˆìŠµë‹ˆë‹¤.'
    else:
        delta_str = 'ì „ë‚ ì— ë¹„í•´ í™œë™ëŸ‰ì´ ê°ì†Œí–ˆìŠµë‹ˆë‹¤.'
    
    st.metric(
        cur['ë‚ ì§œ'], 
        value=f'{cur['í™œë™ëŸ‰']:.1f} %', 
        delta=f'{cur['í™œë™ëŸ‰ ë³€í™”']:.1f} %', 
    )
    st.caption(delta_str)
    st.line_chart(df, x='ë‚ ì§œ', y='í™œë™ëŸ‰', x_label='', y_label='', height=300)


"""
ë·° ë°°ì¹˜
"""

st.set_page_config(
    page_title='ë¡œê±´ - ë°˜ë ¤ê²¬ í–‰ë™ ë¶„ì„',
    layout='wide'
)
tab_realtime, tab_log, tab_config = st.tabs(['ğŸ”´ ì‹¤ì‹œê°„ ì˜ìƒ', 'ğŸ“‹ ì „ì²´ í–‰ë™ ê¸°ë¡', 'âš™ï¸ ì„¤ì •'])

with tab_realtime:
    # col1, col2 = st.columns([6, 4])
    # with col1:
    toolbar()
    realtime_image()
    # with col2:
    #     dataframe_brief()
    #     st.caption('ìµœê·¼ì— ê¸°ë¡ëœ í–‰ë™ì´ 10ê°œê¹Œì§€ í‘œì‹œë©ë‹ˆë‹¤.')
    mic_info()
    
with tab_log:
    mic_info()
    col1, col2 = st.columns([1, 4])
    with col1:
        realtime_image()
        st.markdown('##### í™œë™ëŸ‰ ë³€í™”')
        analysis()
    with col2:
        st.markdown('### í–‰ë™ ê¸°ë¡')
        st.session_state.log_filter = st.multiselect(
            label='ê²€ìƒ‰ í•„í„°',
            options=[NODOG] + BEHAVIORS,
            placeholder='ê²€ìƒ‰ ì¡°ê±´ì„ ì¶”ê°€í•˜ì„¸ìš”.'
        )
        entire_dataframes()

with tab_config:
    col1, col2 = st.columns([1, 4])
    with col1:
        realtime_image()
    with col2:
        st.markdown('### ì•Œë¦¼ ì„¤ì •')
        st.session_state.noti_filter = st.multiselect(
            label='ë°˜ë ¤ê²¬ì´ íŠ¹ì • í–‰ë™ì„ í–ˆì„ ë•Œ ì•Œë¦¼ì„ ë°›ìŠµë‹ˆë‹¤.',
            options=BEHAVIORS,
            placeholder='ì•Œë¦¼ì„ ë°›ì„ í–‰ë™ì„ ì„ íƒí•˜ì„¸ìš”.'
        )
        with st.expander('ì•Œë¦¼ìŒ ì„¤ì •'):
            st.session_state.beep = st.radio(
                label='ì•Œë¦¼ìŒ ì„¤ì •', 
                options=list(BEEPS.keys()),
                index=1,
                label_visibility='collapsed'
            )
            if st.session_state.beep:
                st.html(
                    f'<audio autoplay><source src="{BEEPS[st.session_state.beep]}" type="audio/mpeg"></audio>'
                )
        st.markdown('### ì ‘ê·¼ì„± ì„¤ì •')
        st.session_state.is_demo = st.toggle('ì‹œì—° ëª¨ë“œ', value=True)

"""
ì‘ì—… ì½”ë£¨í‹´
"""


@st.fragment(run_every='100ms')
def take_frame():
    frames = st.session_state.frames
    demo_cap = st.session_state.demo_cap
    live_cap = st.session_state.live_cap
    
    frame, timestamp = capture_frame(demo_cap if st.session_state.is_demo else live_cap, FRAME_DIR)
    if frame is None:
        return
    frames.append((frame, timestamp))
take_frame()


@st.fragment(run_every='1s')
def infer():
    frames = st.session_state.frames
    bbox_frames = st.session_state.bbox_frames
    gif_queue = st.session_state.gif_queue
    
    if bbox_frames and isinstance(bbox_frames[-1], tuple):
        _, _, has_dog, behavior = bbox_frames[-1]
    else:
        has_dog = False
        behavior = NODOG
    
    if not frames:
        return
    
    frame, timestamp = frames[-1]
    
    # result = infer_image(frame, has_dog, behavior)
    result = {'bbox_image_path': '_', 'has_dog': True, 'current_class': 'WALK', 'make_gif': False}
    print(f'infer: {result}')
    bbox_image = result['bbox_image_path']
    has_dog = result['has_dog']
    behavior = result['current_class']
    need_gif = result['make_gif']
    
    bbox_frames.append((bbox_image, timestamp, has_dog, behavior))
    
    if need_gif:
        gif_name = f'{timestamp.strftime(r'%Y-%m-%d %H_%M_%S_%f')}.gif'
        gif_queue.append((gif_name, timestamp))
        add_log(timestamp, behavior, os.path.join(CAPTURE_DIR, gif_name))
    
    st.session_state.behavior = behavior
infer()


@st.fragment(run_every='1s')
def gif():
    gif_queue = st.session_state.gif_queue
    print(f'@@@ gif: {gif_queue}')
    DURATION = 10
    
    if not gif_queue:
        return
    
    gif_name, timestamp = gif_queue[0]
    while (datetime.now() - timestamp).total_seconds() > DURATION // 2:
        make_gif(BBOX_DIR, CAPTURE_DIR, gif_name, 10 * DURATION)
        gif_queue.popleft()
        if not gif_queue:
            break
        gif_name, timestamp = gif_queue[0]
gif()


@st.fragment(run_every='1s')
def remove_old_frame():
    print(f'@@@ remove_old_frame')
    frames = st.session_state.frames
    bbox_frames = st.session_state.bbox_frames
    
    while len(frames) > 1000:
        to_remove, _ = frames[0]
        if os.path.exists(to_remove):
            try:
                os.remove(to_remove)
            except Exception as e:
                print(e)
                continue
        frames.popleft()

    while len(bbox_frames) > 1000:
        to_remove, _, _, _ = bbox_frames[0]
        if os.path.exists(to_remove):
            try:
                os.remove(to_remove)
            except Exception as e:
                print(e)
                continue
        bbox_frames.popleft()
remove_old_frame()
