from collections import deque
from datetime import datetime
from random import randint
import streamlit as st
import pandas as pd
import cv2 as cv
import threading
import shutil
import time
import os

from src.img_capture import open_capture, close_capture, capture_frame
from src.analysis import analyse_daily_activity, analyse_total_activity
from src.utils import get_dataframe_row, image_to_base64

LOG_DIR = 'logs'
FRAME_DIR = 'frames'
CAPTURE_DIR = 'captures'
PLACEHOLDER = 'resources/placeholder.png'
CAM_BLIND = 'resources/cam_blind.png'

BEEPS = {
    'ì•Œë¦¼ìŒ ë„ê¸°': '',
    'ê¸°ë³¸ ì•Œë¦¼ìŒ': 'https://www.soundjay.com/buttons/sounds/beep-07a.mp3',
    'ë©ë©': 'https://t1.daumcdn.net/cfile/tistory/99CC98395CE6F54B0A'
}
BEHAVIORS = ['FEETUP', 'SIT', 'WALK', 'LYING', 'BODYSHAKE']
NONE = 'í–‰ë™ ì—†ìŒ'

os.makedirs(FRAME_DIR, exist_ok=True)
os.makedirs(CAPTURE_DIR, exist_ok=True)

frames = os.listdir(FRAME_DIR)
for i in range(len(frames)):
    frame = frames[i]
    timestamp = datetime.strptime(frame[:-4], r'%Y-%m-%d %H_%M_%S_%f')
    frames[i] = (os.path.join(FRAME_DIR, frame), timestamp)
frames = deque(frames)


def load_logs(log_dir='logs/'):
    logs = []
    for file_name in os.listdir(log_dir):
        df = pd.read_csv(os.path.join(log_dir, file_name))
        df['ìº¡ì²˜'] = df['íŒŒì¼'].apply(lambda f: image_to_base64(f, format=f[-3:]) if os.path.exists(f) else '')
        logs.append(df)
    if not logs:
        logs.append(pd.DataFrame(columns=['ë‚ ì§œ', 'ì‹œê°„', 'í–‰ë™', 'ìº¡ì²˜']))
    log = logs.pop()
    logs.reverse()
    return log, logs


def add_log(tiemstamp, behavior, image_path, notify=True):
    row = get_dataframe_row(tiemstamp.date(), tiemstamp.time(), behavior, image_path)
    if st.session_state.log.empty or st.session_state.log.iloc[0]['ë‚ ì§œ'] == row.iloc[0]['ë‚ ì§œ']:
        st.session_state.log = pd.concat([row, st.session_state.log], ignore_index=True)
    else:
        st.session_state.logs.insert(0, st.session_state.log)
        st.session_state.log = row
    if not st.session_state.log.empty:
        st.session_state.log.drop(columns=['ìº¡ì²˜']).to_csv(os.path.join(LOG_DIR, st.session_state.log.iloc[0]['ë‚ ì§œ'] + '.csv'), index=False)
    if notify and behavior in st.session_state.noti_filter:
        st.html(
            f'<audio autoplay><source src="{BEEPS[st.session_state.beep]}" type="audio/mpeg"></audio>'
        )
        st.toast(f'í–‰ë™ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤: {behavior}', icon='ğŸ¶')
    st.session_state.behavior = behavior


"""
ìƒíƒœ ìƒì„±
"""
if 'placeholder' not in st.session_state:
    st.session_state.placeholder = 0 
if 'log' not in st.session_state:
    st.session_state.log, st.session_state.logs = load_logs()
if 'behavior' not in st.session_state:
    st.session_state.behavior = NONE
if 'beep' not in st.session_state:
    st.session_state.beep = list(BEEPS.keys())[1]
if 'noti_filter' not in st.session_state:
    st.session_state.noti_filter = []
if 'log_filter' not in st.session_state:
    st.session_state.log_filter = []
if 'log_expanded' not in st.session_state:
    st.session_state.log_expanded = {}
if 'is_mic_on' not in st.session_state:
    st.session_state.is_mic_on = False
if 'is_cam_on' not in st.session_state:
    st.session_state.is_cam_on = True
if 'is_demo' not in st.session_state:
    st.session_state.is_demo = True


@st.cache_data(ttl='1s')
def get_analysis():
    return analyse_total_activity([st.session_state.log] + st.session_state.logs)


"""
í”„ë˜ê·¸ë¨¼íŠ¸ ìƒì„±
"""
@st.fragment(run_every='1ms')
def realtime_image():
    if st.session_state.is_cam_on:
        image = ''
        if frames := os.listdir(FRAME_DIR):
            image = os.path.join(FRAME_DIR, frames[-1])
        if not os.path.exists(image):
            image = CAM_BLIND
    else:
        image = CAM_BLIND
    st.image(image, use_container_width=True)


@st.fragment(run_every='100ms')
def dataframe_brief():
    st.dataframe(
        st.session_state.log.drop(columns=['íŒŒì¼']).head(10), 
        use_container_width=True, hide_index=True,
        column_config={
            'ìº¡ì²˜': st.column_config.ImageColumn('ìº¡ì²˜', width='large')
        }
    )


@st.fragment(run_every='100ms')
def entire_dataframes():
    has_no_data = True
    is_first = True
    logs = [st.session_state.log] + st.session_state.logs
    with st.container():
        for df in logs:
            if st.session_state.log_filter:
                df = df[df['í–‰ë™'].isin(st.session_state.log_filter)]
            if df.empty:
                continue
            has_no_data = False
            
            date = df.iloc[0]['ë‚ ì§œ']
            if date not in st.session_state.log_expanded:
                st.session_state.log_expanded[date] = is_first
            is_first = False
            
            with st.expander(date, expanded=st.session_state.log_expanded[date]):
                st.dataframe(
                    df.drop(columns=['íŒŒì¼', 'ë‚ ì§œ']), 
                    use_container_width=True, hide_index=True, key=date,
                    column_config={
                        'ì‹œê°„': st.column_config.Column(width='small'),
                        'í–‰ë™': st.column_config.Column(width='small'),
                        'ìº¡ì²˜': st.column_config.ImageColumn('ìº¡ì²˜', width='large')
                    }
                )
        if has_no_data:
            st.caption('í–‰ë™ ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤.')


@st.fragment()
def toolbar():
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.session_state.is_mic_on = st.toggle(
            'ğŸ™ï¸ ë§ˆì´í¬', 
            value=False, 
            help='ì‹¤ì‹œê°„ìœ¼ë¡œ ì „ë‹¬ëœ ìŒì„±ì´ í™ˆìº ì˜ ìŠ¤í”¼ì»¤ì—ì„œ ì¬ìƒë©ë‹ˆë‹¤.'
        )
    with col2:
        st.session_state.is_cam_on = st.toggle(
            'ğŸ“¹ ì¹´ë©”ë¼', 
            value=True, 
            help='í™”ë©´ì—ì„œ ì‹¤ì‹œê°„ ì¹´ë©”ë¼ í™”ë©´ì´ ê°€ë ¤ì§€ì§€ë§Œ, ë…¹í™”ì™€ ë¶„ì„ì€ ê³„ì† ì§„í–‰ë©ë‹ˆë‹¤.'
        )
    with col3:
        if st.button('ìº¡ì³í•˜ê¸°', icon='ğŸ“¸', use_container_width=True) and frames:
            image, timestamp = frames[-1]
            shutil.copy(image, CAPTURE_DIR)
            add_log(timestamp, st.session_state.behavior, os.path.join(CAPTURE_DIR, os.path.basename(image)), notify=False)
            st.toast('ìº¡ì³ëœ ì´ë¯¸ì§€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.', icon='ğŸ“¸')
    with col4:
        if st.button('ì €ì¥ì†Œ ì—´ê¸°', icon='ğŸ“‚', use_container_width=True):
            os.startfile(CAPTURE_DIR, 'open')


@st.fragment(run_every='100ms')
def mic_info():
    if st.session_state.is_mic_on:
        st.info('ë§ˆì´í¬ê°€ ì¼œì ¸ìˆìŠµë‹ˆë‹¤!', icon='ğŸ™ï¸')
    else:
        st.empty()


@st.fragment(run_every='5s')
def analysis():
    df = analyse_total_activity([st.session_state.log] + st.session_state.logs)
    cur = df.iloc[len(df) - 1]
    
    if -5.0 <= cur['í™œë™ëŸ‰ ë³€í™”'] <= 5.0:
        delta_str = 'ì „ë‚ ê³¼ ë¹„êµí–ˆì„ ë•Œ í™œë™ëŸ‰ì— í° ë³€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.'
    elif cur['í™œë™ëŸ‰ ë³€í™”'] > 5.0:
        delta_str = 'ì „ë‚ ì— ë¹„í•´ í™œë™ëŸ‰ì´ ì¦ê°€í–ˆìŠµë‹ˆë‹¤.'
    else:
        delta_str = 'ì „ë‚ ì— ë¹„í•´ í™œë™ëŸ‰ì´ ê°ì†Œí–ˆìŠµë‹ˆë‹¤.'
    
    st.metric(
        cur['ë‚ ì§œ'], 
        value=f'{cur['í™œë™ëŸ‰']:.1f} %', 
        delta=f'{cur['í™œë™ëŸ‰ ë³€í™”']:.1f} %', 
    )
    st.caption(delta_str)
    st.line_chart(df, x='ë‚ ì§œ', y='í™œë™ëŸ‰', x_label='', y_label='', height=300)


"""
ë·° ë°°ì¹˜
"""
st.set_page_config(
    page_title='ë¡œê±´ - ë°˜ë ¤ê²¬ í–‰ë™ ë¶„ì„',
    layout='wide'
)
tab_realtime, tab_log, tab_config = st.tabs(['ğŸ”´ ì‹¤ì‹œê°„ ì˜ìƒ', 'ğŸ“‹ ì „ì²´ í–‰ë™ ê¸°ë¡', 'âš™ï¸ ì„¤ì •'])

with tab_realtime:
    col1, col2 = st.columns([6, 4])
    with col1:
        realtime_image()
        toolbar()
    with col2:
        dataframe_brief()
        st.caption('ìµœê·¼ì— ê¸°ë¡ëœ í–‰ë™ì´ 10ê°œê¹Œì§€ í‘œì‹œë©ë‹ˆë‹¤.')
    mic_info()
    
with tab_log:
    mic_info()
    col1, col2 = st.columns([1, 4])
    with col1:
        realtime_image()
        st.markdown('##### í™œë™ëŸ‰ ë³€í™”')
        analysis()
    with col2:
        st.markdown('### í–‰ë™ ê¸°ë¡')
        st.session_state.log_filter = st.multiselect(
            label='ê²€ìƒ‰ í•„í„°',
            options=[NONE] + BEHAVIORS,
            placeholder='ê²€ìƒ‰ ì¡°ê±´ì„ ì¶”ê°€í•˜ì„¸ìš”.'
        )
        entire_dataframes()

with tab_config:
    col1, col2 = st.columns([1, 4])
    with col1:
        realtime_image()
    with col2:
        st.markdown('### ì•Œë¦¼ ì„¤ì •')
        st.session_state.noti_filter = st.multiselect(
            label='ë°˜ë ¤ê²¬ì´ íŠ¹ì • í–‰ë™ì„ í–ˆì„ ë•Œ ì•Œë¦¼ì„ ë°›ìŠµë‹ˆë‹¤.',
            options=BEHAVIORS,
            placeholder='ì•Œë¦¼ì„ ë°›ì„ í–‰ë™ì„ ì„ íƒí•˜ì„¸ìš”.'
        )
        with st.expander('ì•Œë¦¼ìŒ ì„¤ì •'):
            st.session_state.beep = st.radio(
                label='ì•Œë¦¼ìŒ ì„¤ì •', 
                options=list(BEEPS.keys()),
                index=1,
                label_visibility='collapsed'
            )
            if st.session_state.beep:
                st.html(
                    f'<audio autoplay><source src="{BEEPS[st.session_state.beep]}" type="audio/mpeg"></audio>'
                )
        st.markdown('### ì ‘ê·¼ì„± ì„¤ì •')
        st.session_state.is_demo = st.toggle('ì‹œì—° ëª¨ë“œ', True)


"""
ì‘ì—… ìŠ¤ë ˆë“œ
"""
def take_frame():
    global frames
    
    cap = open_capture()
    while True:
        frame, timestamp = capture_frame(cap, FRAME_DIR)
        if frame is None:
            continue
        frames.append((frame, timestamp))
        time.sleep(0.033)


def remove_old_frame(max_frame):
    global frames
    
    while True:
        while len(frames) > max_frame:
            to_remove, _ = frames[0]
            if os.path.exists(to_remove):
                try:
                    os.remove(to_remove)
                except Exception as e:
                    print(e)
                    continue
            frames.popleft()
        time.sleep(0.033)

threading.Thread(target=take_frame, daemon=True).start()
threading.Thread(target=remove_old_frame, args=(1000,), daemon=True).start()
