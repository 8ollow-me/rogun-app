from torchvision import models
from ultralytics import YOLO
from PIL import Image

import pandas as pd
import numpy as np
import shutil
import time
import cv2
import os

import torch
import torch.nn as nn
import torchvision.transforms as transforms

torch.classes.__path__ = []

# ------------------------
# 1. í™˜ê²½ ì„¤ì •
# ------------------------
NODOG = 'ê°•ì•„ì§€ ì—†ìŒ'
BBOX_DIR = 'bbox'
os.makedirs(BBOX_DIR, exist_ok=True)

# ------------------------
# 2. YOLO ëª¨ë¸ ë¡œë“œ (ê°•ì•„ì§€ íƒì§€)
# ------------------------
yolo_model = YOLO("resources/yolo11m.pt")

# ------------------------
# 3. ResNet ëª¨ë¸ ë¡œë“œ (ê°•ì•„ì§€ ë™ì‘ ë¶„ë¥˜)
# ------------------------
device = 'cuda' if torch.cuda.is_available() else 'cpu'
resnet_model = models.resnet18(weights=None)
num_features = resnet_model.fc.in_features
num_classes = 10
resnet_model.fc = nn.Linear(num_features, num_classes)
resnet_model.load_state_dict(torch.load("resources/resnet18.pth", map_location=device))
resnet_model.to(device)
resnet_model.eval()

# ------------------------
# 4. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ (ResNet ì…ë ¥ìš©)
# ------------------------
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

# ------------------------
# 5. ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (YOLO + ResNet)
# ------------------------
def draw_bounding_box(frame, x1, y1, x2, y2, class_name):
    """
    ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ê·¸ë¦¬ê³ , í´ë˜ìŠ¤ëª… + IDë¥¼ í‘œì‹œí•˜ëŠ” í•¨ìˆ˜.

    Args:
        frame (numpy.ndarray): ì›ë³¸ ì´ë¯¸ì§€
        x1, y1, x2, y2 (int): ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ
        class_name (str): ì˜ˆì¸¡ëœ í´ë˜ìŠ¤ëª…
        object_id (int): ê°ì²´ ID

    Returns:
        frame (numpy.ndarray): ë°”ìš´ë”© ë°•ìŠ¤ê°€ ì¶”ê°€ëœ ì´ë¯¸ì§€
    """
    class_colors = {
        "SIT": (0, 255, 255),
        "WALK": (0, 255, 0),
        "LYING": (255, 0, 255),
        "BODYSHAKE": (255, 0, 0),
        "FEETUP": (0, 0, 255)
    }
    bbox_color = class_colors.get(class_name, (192, 192, 192))

    cv2.rectangle(frame, (x1, y1), (x2, y2), bbox_color, 2)

    label = f"{class_name}"
    font = cv2.FONT_HERSHEY_SIMPLEX
    font_scale = 2
    font_thickness = 2
    text_size = cv2.getTextSize(label, font, font_scale, font_thickness)[0]
    text_w, text_h = text_size
    text_x, text_y = x1, y1 - 5 if y1 > 20 else y1 + 20

    cv2.rectangle(frame, (text_x, text_y - text_h - 4), (text_x + text_w + 4, text_y), bbox_color, -1)
    cv2.putText(frame, label, (text_x + 2, text_y - 2), font, font_scale, (0, 0, 0), font_thickness, cv2.LINE_AA)
    
    return frame

# ------------------------
# 6. ì´ë¯¸ì§€ ì¶”ë¡  í•¨ìˆ˜ (YOLO + ResNet)
# ------------------------
def infer_image(image_path, prev_has_dog, prev_class):
    """
    ì…ë ¥ ì´ë¯¸ì§€ì—ì„œ ê°•ì•„ì§€ë¥¼ ê°ì§€í•˜ê³  ë™ì‘ì„ ë¶„ë¥˜í•˜ëŠ” í•¨ìˆ˜.

    Returns:
        dict: ê²°ê³¼ ì •ë³´ (ë°”ìš´ë”© ë°•ìŠ¤ ì´ë¯¸ì§€ ê²½ë¡œ, ê°•ì•„ì§€ ì¡´ì¬ ì—¬ë¶€, í˜„ì¬ ë™ì‘, GIF ìƒì„± ì—¬ë¶€)
    """
    global yolo_model
    
    frame = cv2.imread(image_path)
    if frame is None:
        print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
        return {"has_dog": prev_has_dog, "current_class": prev_class, "make_gif": False}
    
    # ìš°ì„  ëª©ì ì§€ì— ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ë³µì œ
    shutil.copy(image_path, BBOX_DIR)
    image_path = os.path.join(BBOX_DIR, os.path.basename(image_path))
    
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

    # 1ï¸âƒ£ YOLO íƒì§€
    results = yolo_model(frame_rgb)
    best_box = None
    best_confidence = 0.0

    for result in results:
        for box in result.boxes.data:
            x1, y1, x2, y2, conf, cls = box.tolist()
            if int(cls) == 16 and conf > best_confidence:
                best_confidence = conf
                best_box = (int(x1), int(y1), int(x2), int(y2))

    # 2ï¸âƒ£ ê°•ì•„ì§€ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
    if best_box is None:
        print('ğŸ‘ï¸â€ğŸ—¨ï¸ ê°•ì•„ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.')
        new_image_path = f'{image_path[:-4]} False ê°•ì•„ì§€ ì—†ìŒ.jpg'
        if not os.path.exists(new_image_path):
            os.rename(image_path, new_image_path)
        else:
            os.remove(image_path)
        return {"bbox_image_path": image_path, "has_dog": False, "current_class": NODOG, "make_gif": prev_has_dog}

    # 3ï¸âƒ£ ê°•ì•„ì§€ ì˜ì—­ í¬ë¡­ í›„ ResNetìœ¼ë¡œ ë¶„ë¥˜
    x1, y1, x2, y2 = best_box
    cropped_img = frame_rgb[y1:y2, x1:x2]
    cropped_img_pil = Image.fromarray(cropped_img)
    processed_img = transform(cropped_img_pil).unsqueeze(0)

    with torch.no_grad():
        start_time = time.time()
        outputs = resnet_model(processed_img.to(device))
        end_time = time.time()
        probs = torch.softmax(outputs, dim=1)
        predicted_class = torch.argmax(probs, dim=1).item()
        confidence = probs[0, predicted_class].item()

    current_class = ["BODYLOWER", "BODYSCRATCH", "BODYSHAKE", "FEETUP", "FOOTUP", "LYING", "MOUNTING", "SIT", "TURN", "WALKRUN"][predicted_class]

    # ì¶”ë¡  ì‹œê°„ ê³„ì‚° (ms ë‹¨ìœ„)
    inference_time_ms = (end_time - start_time) * 1000
    print(f"Speed: {inference_time_ms:.2f}ms for ResNet")

    # 4ï¸âƒ£ ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸° (í˜„ì¬ í´ë˜ìŠ¤ ì ìš©)
    frame = draw_bounding_box(frame, x1, y1, x2, y2, current_class)
    cv2.imwrite(image_path, frame)

    # 5ï¸âƒ£ ì´ì „ í´ë˜ìŠ¤ì™€ ë¹„êµí•˜ì—¬ GIF ìƒì„± ì—¬ë¶€ ê²°ì •
    print(f'ğŸ‘ï¸â€ğŸ—¨ï¸ ì¶”ë¡  ê²°ê³¼: {current_class}')
    new_image_path = f'{image_path[:-4]} True {current_class}.jpg'
    if not os.path.exists(new_image_path):
        os.rename(image_path, new_image_path)
    else:
        os.remove(image_path)
    return {"bbox_image_path": image_path, "has_dog": True, "current_class": current_class, "make_gif": prev_class != current_class}
